{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a73e9b3-ec23-4605-b5df-2f94a2b38fbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3313557148.py, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 78\u001b[0;36m\u001b[0m\n\u001b[0;31m    with torch.inference_mode():\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# Redo Model_0\n",
    "# with PyTorch\n",
    "# built in\n",
    "###############\n",
    "\n",
    "# Create a linear model by sublassing nn.Module\n",
    "class LinearRegressionModuleV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        supe().__init__()\n",
    "        # Use nn.Linear() for creating model parameters instead of defining the parameters ourselves.\n",
    "        self.linear_layer = nn.Linear(in_features=1, # also caleed linear transform, probing layer, fully connected layer...\n",
    "                                    out_features=1) # means we want an input of 1, x-value, and output of 1, y-value.\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # 'x:torch.tensor': what's being input '-> toch.Tensor': what's being output\n",
    "            return self.linear_layer(x)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_1 = LinearRegressionModuleV2()\n",
    "model_1.to(device)\n",
    "\n",
    "# Setup loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.01)\n",
    "\n",
    "# Write Training/Testing Loop\n",
    "torch.manual_seed(42)\n",
    "epochs = 200\n",
    "\n",
    "# Put data on the target device:\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_1.train()\n",
    "\n",
    "    # 1. Forward Pass\n",
    "    y_pred = model_1(x_train)\n",
    "\n",
    "    # 2. Calculate loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Backpropogation\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    ### Testing \n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_1(X_test)\n",
    "\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    # print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test}\")\n",
    "\n",
    "\n",
    "### Evaluate the model:\n",
    "model_1.state_dict() # Check state dict.\n",
    "\n",
    "# Make predictions:\n",
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_1(X_test)\n",
    "\n",
    "print(y_preds)\n",
    "plot_predictions(predictions=y_preds.cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603cb8d-4a7c-4a50-9792-534e19507075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
